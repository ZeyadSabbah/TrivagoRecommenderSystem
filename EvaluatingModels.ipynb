{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EvaluatingModels.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoPUgw90QJ/z1yhc4J/jsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeyadSabbah/TrivagoRecommenderSystem/blob/master/EvaluatingModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr51e1l72qbP",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating Models\n",
        "## Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iub6c1H2sYoz",
        "colab_type": "code",
        "outputId": "633401e3-b470-4906-fcc9-795c5d29f993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYhABAowsZ49",
        "colab_type": "code",
        "outputId": "1ec841c0-209a-4db4-9a12-1495bfbc225f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Trivago/Project/TrivagoRecommenderSystem"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Trivago/Project/TrivagoRecommenderSystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp6mufSj25wO",
        "colab_type": "text"
      },
      "source": [
        "## Loading Libraries & Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvIc037-tx2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD665TzttzXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainDataFilepath = '/content/drive/My Drive/Trivago/Datasets/clean_data/TrainData.csv'\n",
        "valFilepath = '/content/drive/My Drive/Trivago/Datasets/clean_data/val.csv'\n",
        "testFilepath = '/content/drive/My Drive/Trivago/Datasets/clean_data/test.csv'\n",
        "\n",
        "TrainData = pd.read_csv(TrainDataFilepath)\n",
        "valData = pd.read_csv(valFilepath)\n",
        "testData = pd.read_csv(testFilepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWStv6Tbrwr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GlobalPath = '/content/drive/My Drive/Trivago/Datasets/clean_data/item_global.csv'\n",
        "GlobalData = pd.read_csv(GlobalPath)\n",
        "GlobalData.drop(columns=['Unnamed: 0', 'properties'], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyUDPJcZ6JHK",
        "colab_type": "text"
      },
      "source": [
        "## Validation & Test sets Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYdrMMb5t2dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#declaring features and label\n",
        "features = ['price', 'item_rank', 'price_rank', 'session_duration', 'item_duration', 'item_session_duration', 'item_interactions', 'maximum_step', 'top_list',\n",
        "            'NumberOfProperties', 'NumberInImpressions', 'NumberInReferences', 'NumberAsClickout', 'NumberAsFinalClickout', 'FClickoutToImpressions',\n",
        "            'FClickoutToReferences', 'FClickoutToClickout', 'MeanPrice', 'AveragePriceRank']\n",
        "label = ['clickout']\n",
        "X_train = TrainData[features]\n",
        "y_train = TrainData[label]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_xDcgECn9cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy=\"median\")),\n",
        "('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "full_pipeline = ColumnTransformer([\n",
        "(\"num\", num_pipeline, list(X_train))\n",
        "])\n",
        "\n",
        "X_train_scaled = full_pipeline.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilUT4LmSq5Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_clickout(data):\n",
        "  data_clickout = data[data['action_type']=='clickout item'].groupby('session_id').tail(1)\n",
        "  return data_clickout\n",
        "\n",
        "def get_item_id(data_clickout):\n",
        "  item_id = data_clickout[['session_id', 'impressions']]\n",
        "  item_id['impressions'] = item_id['impressions'].apply(lambda x: x.split('|'))\n",
        "  item_id = item_id.explode('impressions')\n",
        "  item_id = item_id.rename(columns={'impressions':'item_id'})\n",
        "  item_id = item_id.reset_index(drop=True)\n",
        "  return item_id\n",
        "\n",
        "def get_price(data_clickout):\n",
        "  price = data_clickout[['session_id', 'prices']]\n",
        "  price['prices'] = price['prices'].apply(lambda x: x.split('|'))\n",
        "  price = price.explode('prices')\n",
        "  price['prices'] = price['prices'].apply(lambda x: int(x))\n",
        "  price = price.rename(columns={'prices':'price'})\n",
        "  price = price.reset_index(drop=True)\n",
        "  return price\n",
        "\n",
        "def get_item_rank(data_clickout):\n",
        "  item_rank = data_clickout[['session_id', 'impressions']]\n",
        "  item_rank['impressions'] = item_rank['impressions'].apply(lambda x: x.split('|'))\n",
        "  item_rank['impressions'] = item_rank['impressions'].apply(lambda x: list(range(1, len(x) + 1)))\n",
        "  item_rank = item_rank.explode('impressions')\n",
        "  item_rank = item_rank.rename(columns={'impressions':'item_rank'})\n",
        "  item_rank = item_rank.reset_index(drop=True)\n",
        "  return item_rank\n",
        "\n",
        "def get_price_rank(data):\n",
        "  price_rank = data.groupby('session_id', sort=False).price.apply(lambda x: x.values).to_frame().reset_index().rename(columns={'price':'price_list'})\n",
        "  price_rank.price_list = price_rank.price_list.apply(lambda x: np.argsort(x))\n",
        "  price_rank = price_rank.rename(columns={'price_list':'price_rank'})\n",
        "  price_rank = price_rank.explode('price_rank')\n",
        "  price_rank = price_rank.reset_index(drop=True)\n",
        "  return price_rank\n",
        "\n",
        "def get_clickout(data_clickout, item_id):\n",
        "  clickout = data_clickout[['session_id','reference']]\n",
        "  clickout = item_id.merge(clickout, on='session_id', how='left')\n",
        "  clickout['clickout'] = clickout.apply(lambda x: 1 if x['item_id'] == x['reference'] else 0, axis=1)\n",
        "  clickout.drop(columns='reference', inplace=True)\n",
        "  clickout = clickout.reset_index(drop=True)\n",
        "  return clickout\n",
        "\n",
        "def get_session_duration(data, item_id):\n",
        "  session_duration = data.groupby('session_id', sort=False).timestamp.max() - data.groupby('session_id', sort=False).timestamp.min()\n",
        "  session_duration = session_duration.to_frame().rename(columns={'timestamp':'session_duration'})\n",
        "  session_duration = item_id.merge(session_duration, on='session_id', how='left')\n",
        "  session_duration.drop(columns='item_id', inplace=True)\n",
        "  session_duration = session_duration.reset_index(drop=True)\n",
        "  return session_duration\n",
        "\n",
        "def get_item_duration(data, item_id):\n",
        "  item_duration = data.groupby(['session_id', 'reference'], sort=False).timestamp.max() - data.groupby(['session_id', 'reference'], sort=False).timestamp.min()\n",
        "  item_duration = item_duration.reset_index().rename(columns={'reference':'item_id', 'timestamp':'item_duration'})\n",
        "  item_duration = item_id.merge(item_duration, left_on=['session_id', 'item_id'], right_on=['session_id', 'item_id'], how='left')\n",
        "  item_duration = item_duration.fillna(0)\n",
        "  item_duration = item_duration.reset_index(drop=True)\n",
        "  return item_duration\n",
        "\n",
        "def get_item_session_duration(item_duration, session_duration):\n",
        "  item_duration['item_session_duration'] = item_duration.item_duration/session_duration.session_duration\n",
        "  item_session_duration = item_duration[['session_id', 'item_id', 'item_session_duration']]\n",
        "  item_duration = item_duration[['session_id', 'item_id', 'item_duration']]\n",
        "  item_session_duration = item_session_duration.fillna(0)\n",
        "  item_session_duration = item_session_duration.reset_index(drop=True)\n",
        "  return item_session_duration\n",
        "\n",
        "def get_item_interactions(data, item_id):\n",
        "  item_interactions = data.groupby(['session_id', 'reference']).step.count().to_frame().reset_index()\n",
        "  item_interactions = item_interactions.rename(columns={'reference':'item_id', 'step':'item_interactions'})\n",
        "  item_interactions = item_id.merge(item_interactions, left_on=['session_id', 'item_id'], right_on=['session_id', 'item_id'], how='left')\n",
        "  item_interactions = item_interactions.fillna(0)\n",
        "  item_interactions = item_interactions.reset_index(drop=True)\n",
        "  return item_interactions\n",
        "\n",
        "def get_maximum_step(data, item_id):\n",
        "  maximum_step = data.groupby('session_id', sort=False).step.max().to_frame().reset_index()\n",
        "  maximum_step = maximum_step.rename(columns={'step':'maximum_step'})\n",
        "  maximum_step = item_id.merge(maximum_step, on='session_id', how='left')\n",
        "  maximum_step = maximum_step.reset_index(drop=True)\n",
        "  return maximum_step\n",
        "\n",
        "def get_top_list(item_rank):\n",
        "  top_list = item_rank[['session_id', 'item_rank']]\n",
        "  top_list['top_list'] = top_list.apply(lambda x: 1 if x['item_rank'] < 6 else 0, axis=1)\n",
        "  top_list = top_list.reset_index(drop=True)\n",
        "  return top_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II42nqhnq6WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_data(data):\n",
        "  FinalClickoutDF = get_data_clickout(data)\n",
        "  item_id = get_item_id(FinalClickoutDF)\n",
        "  price = get_price(FinalClickoutDF)\n",
        "  item_rank = get_item_rank(FinalClickoutDF)\n",
        "  price_rank = get_price_rank(price)\n",
        "  clickout = get_clickout(FinalClickoutDF, item_id)\n",
        "  session_duration = get_session_duration(data, item_id)\n",
        "  item_duration = get_item_duration(data, item_id)\n",
        "  item_session_duration = get_item_session_duration(item_duration, session_duration)\n",
        "  item_interactions = get_item_interactions(data, item_id)\n",
        "  maximum_step = get_maximum_step(data, item_id)\n",
        "  top_list = get_top_list(item_rank)\n",
        "  \n",
        "  local_data = item_id.copy()\n",
        "  local_data['price'] = price.price\n",
        "  local_data['item_rank'] = item_rank.item_rank\n",
        "  local_data['price_rank'] = price_rank.price_rank\n",
        "  local_data['clickout'] = clickout.clickout\n",
        "  local_data['session_duration'] = session_duration.session_duration\n",
        "  local_data['item_duration'] = item_duration.item_duration\n",
        "  local_data['item_session_duration'] = item_session_duration.item_session_duration\n",
        "  local_data['item_interactions'] = item_interactions.item_interactions\n",
        "  local_data['maximum_step'] = maximum_step.maximum_step\n",
        "  local_data['top_list'] = top_list.top_list\n",
        "  GlobalPath = '/content/drive/My Drive/Trivago/Datasets/clean_data/item_global.csv'\n",
        "  GlobalData = pd.read_csv(GlobalPath)\n",
        "  GlobalData.item_id = GlobalData.item_id.apply(lambda x: str(x))\n",
        "  data = local_data.merge(GlobalData, on='item_id', how='left')\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unvomcF21veg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy=\"median\")),\n",
        "('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "full_pipeline = ColumnTransformer([\n",
        "(\"num\", num_pipeline, list(X_train))\n",
        "]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lOepgZk2ird",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#validation set transformation and scaling\n",
        "valData = transform_data(valData)\n",
        "valData_sessions_item = valData[['session_id', 'item_id']]\n",
        "X_val = valData[features]\n",
        "y_val = valData[label]\n",
        "\n",
        "X_val_scaled = full_pipeline.fit_transform(X_val)\n",
        "X_val_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tz_G0TVk2Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test set transformation and scaling\n",
        "testData = transform_data(testData)\n",
        "testData_sessions_item = testData[['session_id', 'item_id']]\n",
        "X_test = testData[features]\n",
        "y_test  = testData[label]\n",
        "\n",
        "X_test_scaled = full_pipeline.fit_transform(X_val)\n",
        "X_test_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXoItQMmFst",
        "colab_type": "text"
      },
      "source": [
        "## Mean Reciprocal Rank\n",
        "Mean Reciprocal Rank is a measure to evaluate systems that return a ranked list of answers to queries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDHMnaR4mJBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function is from this page https://gist.github.com/bwhite/3726239\n",
        "def mean_reciprocal_rank(rs):\n",
        "    \"\"\"Score is reciprocal of the rank of the first relevant item\n",
        "    First element is 'rank 1'.  Relevance is binary (nonzero is relevant).\n",
        "    Example from http://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
        "    >>> rs = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.61111111111111105\n",
        "    >>> rs = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0]])\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.5\n",
        "    >>> rs = [[0, 0, 0, 1], [1, 0, 0], [1, 0, 0]]\n",
        "    >>> mean_reciprocal_rank(rs)\n",
        "    0.75\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        Mean reciprocal rank\n",
        "    \"\"\"\n",
        "    rs = (np.asarray(r).nonzero()[0] for r in rs)\n",
        "    return np.mean([1. / (r[0] + 1) if r.size else 0. for r in rs])\n",
        "\n",
        "\n",
        "def r_precision(r):\n",
        "    \"\"\"Score is precision after all relevant documents have been retrieved\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> r_precision(r)\n",
        "    0.33333333333333331\n",
        "    >>> r = [0, 1, 0]\n",
        "    >>> r_precision(r)\n",
        "    0.5\n",
        "    >>> r = [1, 0, 0]\n",
        "    >>> r_precision(r)\n",
        "    1.0\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        R Precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    z = r.nonzero()[0]\n",
        "    if not z.size:\n",
        "        return 0.\n",
        "    return np.mean(r[:z[-1] + 1])\n",
        "\n",
        "\n",
        "def precision_at_k(r, k):\n",
        "    \"\"\"Score is precision @ k\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    >>> r = [0, 0, 1]\n",
        "    >>> precision_at_k(r, 1)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 2)\n",
        "    0.0\n",
        "    >>> precision_at_k(r, 3)\n",
        "    0.33333333333333331\n",
        "    >>> precision_at_k(r, 4)\n",
        "    Traceback (most recent call last):\n",
        "        File \"<stdin>\", line 1, in ?\n",
        "    ValueError: Relevance score length < k\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        Precision @ k\n",
        "    Raises:\n",
        "        ValueError: len(r) must be >= k\n",
        "    \"\"\"\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k] != 0\n",
        "    if r.size != k:\n",
        "        raise ValueError('Relevance score length < k')\n",
        "    return np.mean(r)\n",
        "\n",
        "\n",
        "def average_precision(r):\n",
        "    \"\"\"Score is average precision (area under PR curve)\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
        "    >>> delta_r = 1. / sum(r)\n",
        "    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n",
        "    0.7833333333333333\n",
        "    >>> average_precision(r)\n",
        "    0.78333333333333333\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        Average precision\n",
        "    \"\"\"\n",
        "    r = np.asarray(r) != 0\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.\n",
        "    return np.mean(out)\n",
        "\n",
        "\n",
        "def mean_average_precision(rs):\n",
        "    \"\"\"Score is mean average precision\n",
        "    Relevance is binary (nonzero is relevant).\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.78333333333333333\n",
        "    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n",
        "    >>> mean_average_precision(rs)\n",
        "    0.39166666666666666\n",
        "    Args:\n",
        "        rs: Iterator of relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "    Returns:\n",
        "        Mean average precision\n",
        "    \"\"\"\n",
        "    return np.mean([average_precision(r) for r in rs])\n",
        "\n",
        "\n",
        "def dcg_at_k(r, k, method=0):\n",
        "    \"\"\"Score is discounted cumulative gain (dcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
        "    >>> dcg_at_k(r, 1)\n",
        "    3.0\n",
        "    >>> dcg_at_k(r, 1, method=1)\n",
        "    3.0\n",
        "    >>> dcg_at_k(r, 2)\n",
        "    5.0\n",
        "    >>> dcg_at_k(r, 2, method=1)\n",
        "    4.2618595071429155\n",
        "    >>> dcg_at_k(r, 10)\n",
        "    9.6051177391888114\n",
        "    >>> dcg_at_k(r, 11)\n",
        "    9.6051177391888114\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    Returns:\n",
        "        Discounted cumulative gain\n",
        "    \"\"\"\n",
        "    r = np.asfarray(r)[:k]\n",
        "    if r.size:\n",
        "        if method == 0:\n",
        "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
        "        elif method == 1:\n",
        "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
        "        else:\n",
        "            raise ValueError('method must be 0 or 1.')\n",
        "    return 0.\n",
        "\n",
        "\n",
        "def ndcg_at_k(r, k, method=0):\n",
        "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
        "    Relevance is positive real values.  Can use binary\n",
        "    as the previous methods.\n",
        "    Example from\n",
        "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
        "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
        "    >>> ndcg_at_k(r, 1)\n",
        "    1.0\n",
        "    >>> r = [2, 1, 2, 0]\n",
        "    >>> ndcg_at_k(r, 4)\n",
        "    0.9203032077642922\n",
        "    >>> ndcg_at_k(r, 4, method=1)\n",
        "    0.96519546960144276\n",
        "    >>> ndcg_at_k([0], 1)\n",
        "    0.0\n",
        "    >>> ndcg_at_k([1], 2)\n",
        "    1.0\n",
        "    Args:\n",
        "        r: Relevance scores (list or numpy) in rank order\n",
        "            (first element is the first item)\n",
        "        k: Number of results to consider\n",
        "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
        "    Returns:\n",
        "        Normalized discounted cumulative gain\n",
        "    \"\"\"\n",
        "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
        "    if not dcg_max:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k, method) / dcg_max\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import doctest\n",
        "    doctest.testmod()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXYC4rqrlW_H",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ2RBEtOlhzx",
        "colab_type": "text"
      },
      "source": [
        "### Without Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUSv8x8vlkYr",
        "colab_type": "text"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYJtW8KU44e3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR_model = joblib.load('/content/drive/My Drive/Trivago/Project/TrivagoRecommenderSystem/LR_model.pkl')\n",
        "Predictions = LR_model.predict(X_val_scaled)\n",
        "Probabilities = LR_model.predict_proba(X_val_scaled)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}