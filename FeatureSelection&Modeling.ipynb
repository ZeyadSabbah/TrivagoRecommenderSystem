{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection&Modeling.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNpYDg2anJ2zZ0UZoD7voVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeyadSabbah/TrivagoRecommenderSystem/blob/master/FeatureSelection%26Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4KQO12xlW_E",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection & Modeling\n",
        "## Mounting to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ASgtpTds7f",
        "colab_type": "code",
        "outputId": "99787519-10a5-4bb2-b2d9-a8f7cba89207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCmsKXRJlgJi",
        "colab_type": "code",
        "outputId": "a9df4fc4-08ec-4d11-fb14-b81e99175261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/Trivago/Project/TrivagoRecommenderSystem"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Trivago/Project/TrivagoRecommenderSystem\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TcSAeLLlsUW",
        "colab_type": "text"
      },
      "source": [
        "## Loading Libraries & Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xjWx6VMlxpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import re\n",
        "import random\n",
        "import joblib\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp4p10jNl2Zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainDataFilepath = 'Datasets/clean_data/Sets/train.csv'\n",
        "TrainData = pd.read_csv(TrainDataFilepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD2THYVGu_bU",
        "colab_type": "text"
      },
      "source": [
        "## Using SelectKBest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LfbBngFxI_W",
        "colab_type": "text"
      },
      "source": [
        "TrainData has 20 features. Starting with just 15 important features to see the importance between the different features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0TyJc7W9pHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#declaring features and label\n",
        "X_train = TrainData[['price', 'item_rank', 'price_rank', 'session_duration', 'item_duration', 'item_session_duration', 'item_interactions', 'maximum_step', 'top_list', 'NumberOfProperties',\n",
        "       'NumberInImpressions', 'NumberInReferences', 'NumberAsClickout', 'NumberAsFinalClickout', 'FClickoutToImpressions', 'FClickoutToReferences', 'FClickoutToClickout', 'MeanPrice',\n",
        "       'AveragePriceRank']]\n",
        "y_train = TrainData[['clickout']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0cyd81oxg7b",
        "colab_type": "code",
        "outputId": "1aa36dab-6d0b-4164-f094-220578262824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "bestfeatures = SelectKBest(score_func=chi2, k=15)\n",
        "fit = bestfeatures.fit(X, y)\n",
        "dfscores = pd.DataFrame(fit.scores_)\n",
        "dfcolumns = pd.DataFrame(X.columns)\n",
        "#concat two dataframes for better visualization \n",
        "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
        "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
        "print(featureScores.nlargest(15,'Score'))  #print 10 best features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     Specs         Score\n",
            "4            item_duration  8.882146e+08\n",
            "6        item_interactions  2.450741e+07\n",
            "11      NumberInReferences  1.650767e+07\n",
            "12        NumberAsClickout  4.326980e+06\n",
            "13   NumberAsFinalClickout  3.261157e+06\n",
            "1                item_rank  2.560008e+06\n",
            "5    item_session_duration  2.545062e+06\n",
            "0                    price  8.438415e+05\n",
            "8                 top_list  6.153390e+05\n",
            "17               MeanPrice  2.273722e+05\n",
            "10     NumberInImpressions  1.314937e+05\n",
            "14  FClickoutToImpressions  1.062536e+05\n",
            "9       NumberOfProperties  7.866433e+04\n",
            "15   FClickoutToReferences  6.643049e+04\n",
            "16     FClickoutToClickout  6.460986e+04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZoVswKq0Yr_",
        "colab_type": "text"
      },
      "source": [
        "Scores are high which means the features are relevant to the output, so all of the features will be taken in modeling at first, and then by removing the least important features, the performance of the model will be captured."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RbZ4WMpmdFy",
        "colab_type": "text"
      },
      "source": [
        "TrainData is ready for processing and modeling, while validation and test sets still need to be engineered. There is a ready function that will transform sets into the same form of TrainData.\n",
        "## Scaling Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVn-Nuv9fojU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy=\"median\")),\n",
        "('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "full_pipeline = ColumnTransformer([\n",
        "(\"num\", num_pipeline, list(X_train))\n",
        "])\n",
        "\n",
        "X_train_scaled = full_pipeline.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3xNR1Zp00Cb",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh9EXt9DFQgQ",
        "colab_type": "text"
      },
      "source": [
        "###Without Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMaex4YV04mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_results(results):\n",
        "  print('Best Prams: {}\\n'.format(results.best_params_))\n",
        "\n",
        "  means = results.cv_results_['mean_test_score']\n",
        "  stds = results.cv_results_['std_test_score']\n",
        "  for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
        "    print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq5ECT0GFS3I",
        "colab_type": "text"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54st49XC3aU9",
        "colab_type": "code",
        "outputId": "9cba0415-8359-4295-cc41-fcf3799f64c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "t1  = datetime.now()\n",
        "lr = LogisticRegression()\n",
        "parameters = {\n",
        "    'C':[0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(lr, parameters, cv=5)\n",
        "cv.fit(X_train_scaled, y_train.values.ravel())\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'LR_model.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Prams: {'C': 10}\n",
            "\n",
            "0.965 (+/-0.0) for {'C': 0.01}\n",
            "0.965 (+/-0.0) for {'C': 0.1}\n",
            "0.965 (+/-0.0) for {'C': 1}\n",
            "0.965 (+/-0.0) for {'C': 10}\n",
            "Time taken :  0:25:42.234537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWY_HcMq7Ydw",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gMyuOU_YwFr",
        "colab_type": "text"
      },
      "source": [
        "Training SVM model can take long time with this huge dataset, so this step will be skipped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgl5Lp8w7bCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1  = datetime.now()\n",
        "svc = SVC()\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C':[0.1, 1, 10]\n",
        "}\n",
        "cv = GridSearchCV(svc, parameters, cv = 5)\n",
        "cv.fit(X_train_scaled, y_train.values.ravel())\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'SVC_model.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYz9KG3-Y9e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svc = SVC(C=10, kernel='rbf')\n",
        "svc.fit(X_train_scaled, y_train.values.ravel())\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh0g3PzSEnE2",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiCrz62bErLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "rf = RandomForestClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250],\n",
        "    'max_depth':[2, 4, 8, 16, 32, None]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(rf, parameters, cv=5)\n",
        "cv.fit(X_train_scaled, y_train.values.ravel())\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'RF_model.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIvw4ITOGUyF",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLlC3wgwGXfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "gb = GradientBoostingClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250, 500],\n",
        "    'max_depth':[1, 3, 5, 7, 9],\n",
        "    'learning_rate':[0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(gb, parameters, cv=5)\n",
        "cv.fit(X_train_scaled, y_train.values.ravel())\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'XGB_model.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPdtkjmpIrJL",
        "colab_type": "text"
      },
      "source": [
        "### With SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-iiJGvbdfrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "sm = SMOTE(random_state = 0, ratio = 1)\n",
        "X_SM, y_SM = sm.fit_sample(X_train_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulp3ENn7jbz-",
        "colab_type": "text"
      },
      "source": [
        "Only the same length of the original training set will be randomly selected, so it would not take long time training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3SDJ84HivNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NumberOfExamples = len(X_train_scaled)\n",
        "SM_sample_indeces = np.random.choice(X_SM.index, NumberOfExamples, replace=False)\n",
        "\n",
        "X_SM_sample = []\n",
        "y_SM_sample = []\n",
        "for Index in SM_sample_indeces:\n",
        "  X_SM_sample.append(X_SM[Index])\n",
        "  y_SM_sample.append(y_SM[Index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8qQOquNeHIA",
        "colab_type": "text"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHHfHZUDkhtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1  = datetime.now()\n",
        "lr = LogisticRegression()\n",
        "parameters = {\n",
        "    'C':[0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(lr, parameters, cv=5)\n",
        "cv.fit(X_SM_sample, y_SM_sample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'LR_modelSMOTE.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUyzDrrk5hp",
        "colab_type": "text"
      },
      "source": [
        "#### SVM\n",
        "It will take long time to be trained, so it will be skipped here also, SVM will be used in undersampling method as it has less number of examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BJYT-1vlIN3",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LscsdM1k8Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "rf = RandomForestClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250],\n",
        "    'max_depth':[2, 4, 8, 16, 32, None]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(rf, parameters, cv=5)\n",
        "cv.fit(X_SM_sample, y_SM_sample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'RF_modelSMOTE.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZmsA-hplWBI",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6wcFJsElYvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "gb = GradientBoostingClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250, 500],\n",
        "    'max_depth':[1, 3, 5, 7, 9],\n",
        "    'learning_rate':[0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(gb, parameters, cv=5)\n",
        "cv.fit(X_SM_sample, y_SM_sample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'XGB_modelSMOTE.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXrxy0iGIzXq",
        "colab_type": "text"
      },
      "source": [
        "### With Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ0MjmdBM3-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ClickoutLen = len(y_train[y_train.clickout==1])\n",
        "NotClickoutIndices = y_train[y_train.clickout==0].index\n",
        "ClickoutIndices = y_train[y_train.clickout==1].index\n",
        "NotClickoutRandomIndices = np.random.choice(NotClickoutIndices, ClickoutLen, replace=False)\n",
        "UnderSampleIndices = np.concatenate([ClickoutIndices, NotClickoutRandomIndices])\n",
        "\n",
        "XUnderSample = []\n",
        "yUnderSample = []\n",
        "for Index in UnderSampleIndices.tolist():\n",
        "  XUnderSample.append(X_train_scaled[Index].tolist())\n",
        "  yUnderSample.append([y_train.clickout.values[Index]])\n",
        "XUndderSample = np.array(XUnderSample)\n",
        "yUnderSample = np.array(yUnderSample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwVcgcDOWEAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XUnderSample = np.load('UnderSampleXy/XUnderSample.npy')\n",
        "yUnderSample = np.load('UnderSampleXy/yUnderSample.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIa5D1kKPKPA",
        "colab_type": "text"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2usiLXiaPbv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1  = datetime.now()\n",
        "lr = LogisticRegression()\n",
        "parameters = {\n",
        "    'C':[0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(lr, parameters, cv=5)\n",
        "cv.fit(XUnderSample, yUnderSample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'LR_modelUndersampling.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFw2p3f1POxx",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFMmTanzPlHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c2653574-eb61-456e-bd8d-05e286a363cc"
      },
      "source": [
        "t1  = datetime.now()\n",
        "svc = SVC()\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C':[0.1, 1, 10]\n",
        "}\n",
        "cv = GridSearchCV(svc, parameters, cv = 5)\n",
        "cv.fit(XUnderSample, yUnderSample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'SVC_modelUndersampling.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1qrawgNPRir",
        "colab_type": "text"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8pkq-8vPtaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "rf = RandomForestClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250],\n",
        "    'max_depth':[2, 4, 8, 16, 32, None]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(rf, parameters, cv=5)\n",
        "cv.fit(XUnderSample, yUnderSample)\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'RF_modelUnderSampling.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTgEqZstPVr_",
        "colab_type": "text"
      },
      "source": [
        "#### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XafehOzWPIiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = datetime.now()\n",
        "gb = GradientBoostingClassifier()\n",
        "parameters = {\n",
        "    'n_estimators':[5, 50, 250, 500],\n",
        "    'max_depth':[1, 3, 5, 7, 9],\n",
        "    'learning_rate':[0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "cv = GridSearchCV(gb, parameters, cv=5)\n",
        "cv.fit(XUnderSample, yUnderSample.values.ravel())\n",
        "\n",
        "print_results(cv)\n",
        "joblib.dump(cv.best_estimator_, 'XGB_model.pkl')\n",
        "t2 = datetime.now()\n",
        "print('Time taken : ', (t2 - t1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}